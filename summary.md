
##  Object Detection on Video inputs Using YOLOv3

<HR>

### [**_Welcome_**](readme.md)&emsp;|&emsp;[Data Set](data-set.md)&emsp;|&emsp;[Jupyter Notebook Code](YOLOv3.ipynb)&emsp;|&emsp;[Summary](summary.md)
<HR>
  
### Content:
1. [Conclusion](#conclusion)
2. [Future Work](#future-work)
3. [References](#references)

<HR>

### Conclusion


In chapter 2 of this project, we were able to detect objects on project. We discuss the changes of measuring mAP on video sequence. We also implemented an algorithm that can search videos based on what is in the video rather than the name of the video.

### Future Work:
<ul>
  <li>Train the Yolov3 network with new classes<li>
  <li>Study the performance of YOLOv3 on real time live data</li>
   <li>Video activity tracking</li>
   <li>Video captioning using RNN and NLP </li>
<ul>

### References
[1] Joseph Redmon., et al., “You Only Look Once: Unified, Real-Time Object Detection”, https://arxiv.org/pdf/1506.02640.pdf, 2015 <br>
[2] Joseph Redmon, Ali Farhadi, “YOLOv3: An Incremental Improvement”, https://arxiv.org/abs/1804.02767 , 2018 <br>
[3] Joseph Redmon, Darknet, https://pjreddie.com/darknet/ <br>
[4] OpenCV: https://docs.opencv.org/4.1.0/ <br>
